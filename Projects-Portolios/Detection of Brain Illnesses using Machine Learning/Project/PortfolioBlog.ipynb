{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> PORTFOLIO BLOG </center>\n",
    "INFO 7390 \n",
    "\n",
    "\n",
    "Vignesh Murali\n",
    "\n",
    "\n",
    "NUID: 001886775\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Alzheimer's Disease?\n",
    "Alzheimer's disease is the most common cause of dementia — a group of brain disorders that cause the loss of intellectual and social skills. In Alzheimer's disease, the brain cells degenerate and die, causing a steady decline in memory and mental function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.nia.nih.gov/sites/default/files/inline-images/brain_slices_alzheimers_0.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://www.nia.nih.gov/sites/default/files/inline-images/brain_slices_alzheimers_0.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we trying to do?\n",
    "In this blog, we are trying to explain how we can build Machine Learning classification models to detect the presence of Alzheimer's Disease using existing medical data.\n",
    "\n",
    "Before we proceed let's define some essential concepts which are to be known.\n",
    "\n",
    "### Supervised Learning: \n",
    "Supervised learning is where you have input variables (x) and an output variable (Y) and you use an algorithm to learn the mapping function from the input to the output.\n",
    "\n",
    "Y = f(X)\n",
    "\n",
    "The goal is to approximate the mapping function so well that when you have new input data (x) that you can predict the output variables (Y) for that data.\n",
    "\n",
    "It is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process. \n",
    "\n",
    "### Classification: \n",
    "A classification model attempts to draw some conclusion from observed values. Given one or more inputs a classification model will try to predict the value of one or more outcomes. Outcomes are labels that can be applied to a dataset. For example, when filtering emails “spam” or “not spam”.\n",
    "\n",
    "There are various classification models in Machine Learning such as Random Forests Classifier and Naive Baye's Classifier.\n",
    "\n",
    "### Neural Networks:\n",
    "Artificial neural networks (ANNs) or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains. \n",
    "\n",
    "Such systems \"learn\" (i.e. progressively improve performance on) tasks by considering examples, generally without task-specific programming.\n",
    "\n",
    "A deep neural network (DNN) is an artificial neural network (ANN) with multiple hidden layers between the input and output layers.\n",
    "\n",
    "## Let's get started!\n",
    "\n",
    "We still start off by obtaining the dataset which we are going to use.\n",
    "\n",
    "The dataset has been obtained from https://www.oasis-brains.org/.\n",
    "\n",
    "- This set consists of a longitudinal collection of 150 subjects aged 60 to 96. Each subject was scanned on two or more visits, separated by at least one year for a total of 373 imaging sessions. \n",
    "- For each subject, 3 or 4 individual T1-weighted MRI scans obtained in single scan sessions are included. The subjects are all right-handed and include both men and women. \n",
    "- 72 of the subjects were characterized as nondemented throughout the study. 64 of the included subjects were characterized as demented at the time of their initial visits and remained so for subsequent scans, including 51 individuals with mild to moderate Alzheimer’s disease. \n",
    "- Another 14 subjects were characterized as nondemented at the time of their initial visit and were subsequently characterized as demented at a later visit.\n",
    "\n",
    "### The first step is to import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from scipy.stats import multivariate_normal\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we clean the dataset of null values and unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('oasis_longitudinal.csv')\n",
    "df2=df\n",
    "df.isnull().sum()\n",
    "df = df.fillna(method='ffill')\n",
    "df.isnull().sum()\n",
    "df = df.drop('Hand',1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready for preprocessing and analysis!\n",
    "\n",
    "It is important to remove irrelevant columns from our dataset because they could affect the performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "We map categorical values to integer values and we standardize our data using StandardScaler() because some classification models perform better with standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Group', axis=1)\n",
    "X = X.drop(['Subject ID','MRI ID','M/F','SES','Visit'], axis=1)\n",
    "y = df['Group']\n",
    "\n",
    "size_mapping={'Demented':1,'Nondemented':2,'Converted':3,'M':4,'F':5}\n",
    "\n",
    "df2['Group'] = df2['Group'].map(size_mapping)\n",
    "\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "X2 = sc_x.fit_transform(X)\n",
    "size_mapping={'Demented':1,'Nondemented':2,'Converted':3,'M':4,'F':5}\n",
    "df2['Group'] = df2['Group'].map(size_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into a Training Set and a Test Set\n",
    "\n",
    "The training set contains a known output and the model learns on this data in order to be generalized to other data later on.\n",
    "\n",
    "We have the test dataset (or subset) in order to test our model’s prediction on this subset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting best features for classification\n",
    "All kinds of tree methods calculate their splits by mathematically determining which split will most effectively help distinguish the classes. \n",
    "\n",
    "This is how the Random Forest method ranks it's features based on their importances depending on which feature allows the best split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1\n",
      "0  63.501291       CDR\n",
      "1  12.377521      MMSE\n",
      "2   8.972169  MR Delay\n",
      "3   4.064768      nWBV\n",
      "4   4.039277       Age\n",
      "5   2.810986       ASF\n",
      "6   2.342095      eTIV\n",
      "7   1.891893      EDUC\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAEKCAYAAACymEqVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFN3ONYFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21397389240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=40, max_depth=5, random_state=1,max_features=5)\n",
    "\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "importances=100*random_forest.feature_importances_\n",
    "sorted_feature_importance = sorted(zip(importances, list(X_train)), reverse=True)\n",
    "features_pd = pd.DataFrame(sorted_feature_importance)\n",
    "print(features_pd)\n",
    "\n",
    "sns.barplot(x=0, y=1, data=features_pd,palette='Reds');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clinical Dementia Rating (CDR) seems to be the most important feature.\n",
    "\n",
    "\n",
    "The Clinical Dementia Rating or CDR is a numeric scale used to quantify the severity of symptoms of dementia.\n",
    "\n",
    "CDR:\n",
    "- 0 No dementia\n",
    "- 0.5 Slightly Dementia\n",
    "- 1 Demented\n",
    "- 2 Severely Demented\n",
    "\n",
    "\n",
    "We may eliminate the 3 lowest features to improve the accuracy of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of data\n",
    "Now as we have cleaned, pre-processed, split and selected features for our dataset, we may finally apply the classification models and view the results produced.\n",
    "\n",
    "### **We start off with the Support Vector Classifier.**\n",
    "\n",
    "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. \n",
    "\n",
    "First we create the model with desired parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://38.media.tumblr.com/0e459c9df3dc85c301ae41db5e058cb8/tumblr_inline_n9xq5hiRsC1rmpjcz.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://38.media.tumblr.com/0e459c9df3dc85c301ae41db5e058cb8/tumblr_inline_n9xq5hiRsC1rmpjcz.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "supvc = SVC(kernel='linear',C=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt to fit our training data into the model we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supvc.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has sucessfully fit the data, we may predict new values using the test data.\n",
    "\n",
    "Then using the accuray_score module from Sci-Kit learn's metrics set, we may view how well the model performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support vector classifier is \n",
      "92.5531914893617\n"
     ]
    }
   ],
   "source": [
    "y_predict = supvc.predict(X_test2)\n",
    "svcscore=accuracy_score(y_test2,y_predict)*100\n",
    "print('Accuracy of Support vector classifier is ')\n",
    "print(100*accuracy_score(y_test2,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us construct the confusion matrix to view the exact number of accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Healthy</th>\n",
       "      <th>Predicted Alzheimers</th>\n",
       "      <th>Predicted Converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Healthy</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Alzheimers</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True converted</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Healthy  Predicted Alzheimers  Predicted Converted\n",
       "True Healthy                     2                     1                    6\n",
       "True Alzheimers                  0                    35                    0\n",
       "True converted                   0                     0                   50"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict),\n",
    "    columns=['Predicted Healthy', 'Predicted Alzheimers','Predicted Converted'],\n",
    "    index=['True Healthy', 'True Alzheimers','True converted']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Extremely low accuracy of 56% when using the RBF kernel.\n",
    "- High computation time on poly kernel & 90% accuracy.\n",
    "- Highest accuracy obtained on the linear kernel with 92.55%.\n",
    "- Accuracy slightly increases when penalty parameter C is set to 2.\n",
    "\n",
    "\n",
    "\n",
    "We have sucessfully classified patients into \"Demented\" or \"Nondemented\" with Support Vector Classifier with an accuracy of 92.55%!\n",
    "\n",
    "##### Similarly, this process can be repeated with several other classification models provided by Sci-Kit Learn to perform classification.\n",
    "\n",
    "You can choose from the following classification models and discover the most accurate one for this cause.\n",
    "http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using Random Forests Classifier**\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.globalsoftwaresupport.com/wp-content/uploads/2018/02/ggff5544hh.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://www.globalsoftwaresupport.com/wp-content/uploads/2018/02/ggff5544hh.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forests Classifier Accuracy is \n",
      "92.5531914893617\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Healthy</th>\n",
       "      <th>Predicted Alzheimers</th>\n",
       "      <th>Predicted Converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Healthy</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Alzheimers</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True converted</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Healthy  Predicted Alzheimers  Predicted Converted\n",
       "True Healthy                     3                     1                    5\n",
       "True Alzheimers                  1                    34                    0\n",
       "True converted                   0                     0                   50"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict = random_forest.predict(X_test)\n",
    "rfscore = 100*accuracy_score(y_test, y_predict)\n",
    "print('Accuracy of Random Forests Classifier Accuracy is ')\n",
    "print(100*accuracy_score(y_test,y_predict))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict),\n",
    "    columns=['Predicted Healthy', 'Predicted Alzheimers','Predicted Converted'],\n",
    "    index=['True Healthy', 'True Alzheimers','True converted']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The highest accuracy was attained when max_features was set to 5.\n",
    "- When 5 features are considered for the best split, we obtain the greatest accuracy in this model (92.55%)\n",
    "- Standardization does not make a difference to the accuracy.\n",
    "\n",
    "\n",
    "### **Using K Nearest Neighbors**\n",
    "\n",
    "K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://adataanalyst.com/wp-content/uploads/2016/07/kNN-1.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://adataanalyst.com/wp-content/uploads/2016/07/kNN-1.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K Nearest Neighbors Classifier is \n",
      "88.29787234042553\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Healthy</th>\n",
       "      <th>Predicted Alzheimers</th>\n",
       "      <th>Predicted Converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Healthy</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Alzheimers</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True converted</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Healthy  Predicted Alzheimers  Predicted Converted\n",
       "True Healthy                     0                     3                    6\n",
       "True Alzheimers                  1                    34                    0\n",
       "True converted                   1                     0                   49"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "nneighbor = KNeighborsClassifier(n_neighbors=8,metric='euclidean')\n",
    "nneighbor.fit(X_train2, y_train2)\n",
    "y_predict = nneighbor.predict(X_test2)\n",
    "knscore = 100*accuracy_score(y_test2, y_predict)\n",
    "print('Accuracy of K Nearest Neighbors Classifier is ')\n",
    "print(100*accuracy_score(y_test2,y_predict))\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test2, y_predict),\n",
    "    columns=['Predicted Healthy', 'Predicted Alzheimers','Predicted Converted'],\n",
    "    index=['True Healthy', 'True Alzheimers','True converted']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Accuracy plateaus after using 8 neighbors.\n",
    "- Accuracy remains the same with all distance measures ( minkowski, manhattan, euclidean ).\n",
    "\n",
    "\n",
    "### **Using Decision Tree Classifier**\n",
    "\n",
    "Decision tree learning uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://dataaspirant.com/wp-content/uploads/2017/01/B03905_05_01-compressor.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://dataaspirant.com/wp-content/uploads/2017/01/B03905_05_01-compressor.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier is \n",
      "77.6595744680851\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Healthy</th>\n",
       "      <th>Predicted Alzheimers</th>\n",
       "      <th>Predicted Converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Healthy</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Alzheimers</th>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True converted</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Healthy  Predicted Alzheimers  Predicted Converted\n",
       "True Healthy                     3                     1                    5\n",
       "True Alzheimers                  8                    27                    0\n",
       "True converted                   7                     0                   43"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dectree = DecisionTreeClassifier(max_features=5)\n",
    "dectree.fit(X_train, y_train)\n",
    "y_predict = dectree.predict(X_test)\n",
    "decscore=100*accuracy_score(y_test, y_predict)\n",
    "print('Accuracy of Decision Tree Classifier is ')\n",
    "print(100*accuracy_score(y_test,y_predict))\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict),\n",
    "    columns=['Predicted Healthy', 'Predicted Alzheimers','Predicted Converted'],\n",
    "    index=['True Healthy', 'True Alzheimers','True converted']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Max_features is selected as 5, this means that when 5 features are selected for the best split, accuracy is the highest.\n",
    "\n",
    "### **Using Naive Baye's Classifier**\n",
    "\n",
    "Naive Bayes is a kind of classifier which uses the Bayes Theorem. It predicts membership probabilities for each class such as the probability that given record or data point belongs to a particular class.  The class with the highest probability is considered as the most likely class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.saedsayad.com/images/Bayes_rule.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://www.saedsayad.com/images/Bayes_rule.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier is \n",
      "90.42553191489363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Healthy</th>\n",
       "      <th>Predicted alzheimers</th>\n",
       "      <th>Predicted Converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Healthy</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True alzheimers</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True converted</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Healthy  Predicted alzheimers  Predicted Converted\n",
       "True Healthy                     2                     1                    6\n",
       "True alzheimers                  2                    33                    0\n",
       "True converted                   0                     0                   50"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "y_predict = gnb.predict(X_test)\n",
    "nbscore = 100*accuracy_score(y_test, y_predict)\n",
    "print('Accuracy of Naive Bayes Classifier is ')\n",
    "print(100*accuracy_score(y_test,y_predict))\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict),\n",
    "    columns=['Predicted Healthy', 'Predicted alzheimers','Predicted Converted'],\n",
    "    index=['True Healthy', 'True alzheimers','True converted']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Parameters have not been tuned because the only parameter available for tuning is priors (Prior probabilities of the class).\n",
    "- It is best to leave priors at 'None' because the priors will be adjusted automatically based on the data.\n",
    "\n",
    "### **Using Ada Boost Classifier**\n",
    "\n",
    "Ada-boost classifier combines weak classifier algorithm to form strong classifier. A single algorithm may classify the objects poorly. But if we combine multiple classifiers with selection of training set at every iteration and assigning right amount of weight in final voting, we can have good accuracy score for overall classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.researchgate.net/profile/Brendan_Marsh3/publication/306054843/figure/fig3/AS:393884896120846@1470920885933/Training-of-an-AdaBoost-classifier-The-first-classifier-trains-on-unweighted-data-then.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.researchgate.net/profile/Brendan_Marsh3/publication/306054843/figure/fig3/AS:393884896120846@1470920885933/Training-of-an-AdaBoost-classifier-The-first-classifier-trains-on-unweighted-data-then.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ADA Boost classifier is \n",
      "90.42553191489363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Healthy</th>\n",
       "      <th>Predicted Alzheimers</th>\n",
       "      <th>Predicted Converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Healthy</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True alzheimers</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True converted</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Healthy  Predicted Alzheimers  Predicted Converted\n",
       "True Healthy                     0                     3                    6\n",
       "True alzheimers                  0                    35                    0\n",
       "True converted                   0                     0                   50"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(algorithm='SAMME')\n",
    "abc.fit(X_train2,y_train2)\n",
    "y_predict = abc.predict(X_test2)\n",
    "abcscore=accuracy_score(y_test2,y_predict)*100\n",
    "print('Accuracy of ADA Boost classifier is ')\n",
    "print(100*accuracy_score(y_test2,y_predict))\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test2, y_predict),\n",
    "    columns=['Predicted Healthy', 'Predicted Alzheimers','Predicted Converted'],\n",
    "    index=['True Healthy', 'True alzheimers','True converted']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Yields higher accuracy when the algorithm used is SAMME and not the default SAMME.R.\n",
    "- SAMME is a boosting algorithm which works better for multiclass classification, SAMME.R works is conventionally used for binary classification problems.\n",
    "- Accuracy greatly increases after using standardised data(From 50% to 90%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Multilayered Perceptron Classifier\n",
    "\n",
    "Multilayer perceptron classifier is a classifier based on the feedforward artificial neural network. MLPC consists of multiple layers of nodes. Each layer is fully connected to the next layer in the network. Nodes in the input layer represent the input data. All other nodes map inputs to outputs by a linear combination of the inputs with the node’s weights w and bias b and applying an activation function.\n",
    "\n",
    "We are using 3 hidden layers of nodes. \n",
    "\n",
    "The solver is used for weight optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.researchgate.net/profile/Mouhammd_Alkasassbeh/publication/309592737/figure/fig2/AS:423712664100865@1478032379613/MultiLayer-Perceptron-MLP-sturcture-334-MultiLayer-Perceptron-Classifier-MultiLayer.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.researchgate.net/profile/Mouhammd_Alkasassbeh/publication/309592737/figure/fig2/AS:423712664100865@1478032379613/MultiLayer-Perceptron-MLP-sturcture-334-MultiLayer-Perceptron-Classifier-MultiLayer.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.1063829787234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Healthy</th>\n",
       "      <th>Predicted Alzheimers</th>\n",
       "      <th>Predicted Converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Healthy</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True alzheimers</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True converted</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Healthy  Predicted Alzheimers  Predicted Converted\n",
       "True Healthy                     3                     1                    5\n",
       "True alzheimers                  3                    32                    0\n",
       "True converted                   5                     0                   45"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=500,solver='lbfgs',hidden_layer_sizes=(10,30,20),activation='tanh')\n",
    "mlp.fit(X_train2,y_train2)\n",
    "y_predict = mlp.predict(X_test2)\n",
    "mlpscore = 100*accuracy_score(y_test2,y_predict)\n",
    "print(mlpscore)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test2, y_predict),\n",
    "    columns=['Predicted Healthy', 'Predicted Alzheimers','Predicted Converted'],\n",
    "    index=['True Healthy', 'True alzheimers','True converted']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Performance greatly increased from 50% to 81.23% after using scaled data.\n",
    "- Accuracy remains unaffected on changing activation functions.\n",
    "- According to scikit learn documentation, the solver 'lbfgs' is more appropriate for smaller datasets compared to other solvers such as 'adam'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using a Feed Forward Deep Learning Neural Network\n",
    "\n",
    "[This Code was Adapted From: https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/ Author: Jason Brownlee]\n",
    "\n",
    "The feedforward neural network was the first and simplest type of artificial neural network devised. In this network, the information moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Architecture/images/feedforward.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Architecture/images/feedforward.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Multi-class labels need to be converted to binary labels(belong or does not belong to the class). LabelBinarizer makes this process easy with the transform method. At prediction time, one assigns the class for which the corresponding model gave the greatest confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train3 =lb.fit_transform(y_train2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Keras library provides a convenient wrapper for deep learning models to be used as classification or regression estimators in scikit-learn. \n",
    "- The KerasClassifier class in Keras take an argument build_fn which is the name of the function to call to get your model. You must define a function that defines your model, compiles it and returns it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "\tclassifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "\tclassifier.add(Dense(activation = 'relu',  input_dim = 8, units = 8, kernel_initializer = 'uniform'))\n",
    "# Adding the second hidden layer\n",
    "\tclassifier.add(Dense( activation = 'relu', units = 15, kernel_initializer = 'uniform'))\n",
    "# Adding the third hidden layer\n",
    "\n",
    "\n",
    "# Adding the output layer\n",
    "\tclassifier.add(Dense(activation = 'sigmoid', units = 3, kernel_initializer = 'uniform' ))\n",
    "\n",
    "# Compiling the ANN\n",
    "\tclassifier.compile(optimizer = 'adamax', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "\treturn classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the example below, it is called \"baseline_model\". We pass this function name to the KerasClassifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=150, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model is automatically bundled up and passed on to the fit() function which is called internally by the KerasClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21396fedb70>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = estimator.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.5531914893617"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffdnscore = 100*accuracy_score(y_test2,y_predict)\n",
    "ffdnscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Healthy</th>\n",
       "      <th>Predicted Alzheimers</th>\n",
       "      <th>Predicted Converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Healthy</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True alzheimers</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True converted</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Healthy  Predicted Alzheimers  Predicted Converted\n",
       "True Healthy                     2                     1                    6\n",
       "True alzheimers                  0                    35                    0\n",
       "True converted                   0                     0                   50"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test2, y_predict),\n",
    "    columns=['Predicted Healthy', 'Predicted Alzheimers','Predicted Converted'],\n",
    "    index=['True Healthy', 'True alzheimers','True converted']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Using the Adamax optimizer we obtain the highest accuracy.\n",
    "- We start with the input layer, followed by two hidden layers with relu activation functions.\n",
    "- The output layer is added and the model is compiled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing our classification models\n",
    "We have run all five classifiers and obtained the accuracies for each, we will attempt to visaulize the acccuracies to determine the best possible classifier for predicting Alzheimer's disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy Classifier\n",
      "2  77.659574        DEC\n",
      "6  79.787234        MLP\n",
      "3  88.297872        KNN\n",
      "1  90.425532         NB\n",
      "5  90.425532        ABC\n",
      "7  90.425532       FFDN\n",
      "0  92.553191        SVC\n",
      "4  92.553191         RF\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\napxBIEmNMwgkqXEGgSQ1ziCQpMb9f+fD5zB/3tGCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21399e31e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scorearray = [svcscore,nbscore,decscore,knscore,rfscore,abcscore,mlpscore,ffdnscore]\n",
    "score_arr = [{'Classifier':'SVC','Accuracy':svcscore},\n",
    "           {'Classifier':'NB','Accuracy':nbscore},\n",
    "            {'Classifier':'DEC','Accuracy':decscore},\n",
    "            {'Classifier':'KNN','Accuracy':knscore},\n",
    "            {'Classifier':'RF','Accuracy':rfscore}\n",
    "            ,{'Classifier':'ABC','Accuracy':abcscore},\n",
    "            {'Classifier':'MLP','Accuracy':mlpscore},\n",
    "            {'Classifier':'FFDN','Accuracy':ffdnscore}]\n",
    "score_df = pd.DataFrame(score_arr)\n",
    "\n",
    "score_df = score_df.sort_values('Accuracy')\n",
    "print(score_df)\n",
    "\n",
    "sns.barplot(x=\"Classifier\", y=\"Accuracy\", data=score_df,palette='Reds');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can hence clearly observe that the best classifier is the Support Vector Classifier & Random Forest Classifier with 92.55% accuracy.\n",
    "\n",
    "- The deep learning Multilayer Perceptron with 3 layers yields 87% accuracy, this could possibly be due to the small size of the dataset resulting in overfitting of the model.\n",
    "\n",
    "- The Deep Learning Network Using Keras Classifier performs better than a tri-layered MLP but the conventional classifiers outperform this network.\n",
    "\n",
    "- The other classifiers' performances were average with the Decision Tree Classifier being the worst performer with 77.12% accuracy.\n",
    "\n",
    "- Since Neural Networks are stochastic in nature, they produce random results every time.\n",
    "\n",
    "- Conventional Machine Learning classifiers perform better than Neural Network models. This could possibly be due to the small size of the dataset which in turn leads to the model overfitting the data. Regularization and data augmentation can be used to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you!\n",
    "I hope this tutorial was helpful, if you have any questions please e-mail me at murali.v@husky.neu.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
